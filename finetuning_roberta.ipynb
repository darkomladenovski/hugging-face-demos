{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>comment</th>\n",
       "      <th>antagonize</th>\n",
       "      <th>antagonize:confidence</th>\n",
       "      <th>condescending</th>\n",
       "      <th>condescending:confidence</th>\n",
       "      <th>dismissive</th>\n",
       "      <th>dismissive:confidence</th>\n",
       "      <th>generalisation</th>\n",
       "      <th>generalisation:confidence</th>\n",
       "      <th>generalisation_unfair</th>\n",
       "      <th>generalisation_unfair:confidence</th>\n",
       "      <th>healthy</th>\n",
       "      <th>healthy:confidence</th>\n",
       "      <th>hostile</th>\n",
       "      <th>hostile:confidence</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcastic:confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2319157561</td>\n",
       "      <td>4</td>\n",
       "      <td>Three marriages, several bankrupt periods, inh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1739464982</td>\n",
       "      <td>4</td>\n",
       "      <td>The sense of entitlement among high school 'jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1739457583</td>\n",
       "      <td>5</td>\n",
       "      <td>So what? He was just stating the obvious.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8121</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5928</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2319156950</td>\n",
       "      <td>40</td>\n",
       "      <td>If one is a Con, why yes, one would honk. Loud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9239</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2327196492</td>\n",
       "      <td>3</td>\n",
       "      <td>Ooohhh... It's Wendy Whiner... making sure to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id  _trusted_judgments  \\\n",
       "0  2319157561                   4   \n",
       "1  1739464982                   4   \n",
       "2  1739457583                   5   \n",
       "3  2319156950                  40   \n",
       "4  2327196492                   3   \n",
       "\n",
       "                                             comment  antagonize  \\\n",
       "0  Three marriages, several bankrupt periods, inh...           0   \n",
       "1  The sense of entitlement among high school 'jo...           0   \n",
       "2          So what? He was just stating the obvious.           0   \n",
       "3  If one is a Con, why yes, one would honk. Loud...           0   \n",
       "4  Ooohhh... It's Wendy Whiner... making sure to ...           0   \n",
       "\n",
       "   antagonize:confidence  condescending  condescending:confidence  dismissive  \\\n",
       "0                 1.0000              0                    1.0000           0   \n",
       "1                 0.7634              0                    0.7634           0   \n",
       "2                 0.8121              0                    0.5928           0   \n",
       "3                 0.8508              0                    0.8867           0   \n",
       "4                 1.0000              0                    1.0000           0   \n",
       "\n",
       "   dismissive:confidence  generalisation  generalisation:confidence  \\\n",
       "0                 1.0000               0                     1.0000   \n",
       "1                 0.7634               0                     1.0000   \n",
       "2                 0.8043               0                     1.0000   \n",
       "3                 0.9239               0                     0.8863   \n",
       "4                 1.0000               0                     1.0000   \n",
       "\n",
       "   generalisation_unfair  generalisation_unfair:confidence  healthy  \\\n",
       "0                    0.0                               1.0        1   \n",
       "1                    0.0                               1.0        1   \n",
       "2                    0.0                               1.0        1   \n",
       "3                    0.0                               1.0        1   \n",
       "4                    0.0                               1.0        1   \n",
       "\n",
       "   healthy:confidence  hostile  hostile:confidence  sarcastic  \\\n",
       "0              0.7578        0              0.7565          0   \n",
       "1              0.7634        0              0.7634          0   \n",
       "2              0.6163        0              1.0000          0   \n",
       "3              0.8508        0              0.9641          0   \n",
       "4              1.0000        0              1.0000          0   \n",
       "\n",
       "   sarcastic:confidence  \n",
       "0                1.0000  \n",
       "1                0.7634  \n",
       "2                1.0000  \n",
       "3                0.8868  \n",
       "4                1.0000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('data/unhealthy_comment_corpus/train.csv')\n",
    "test_data = pd.read_csv('data/unhealthy_comment_corpus/test.csv')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['unhealthy'] = np.where(train_data['healthy'] == 1, 0, 1)\n",
    "attributes = ['antagonize', 'condescending', 'dismissive', 'generalisation', 'generalisation_unfair', 'hostile', 'sarcastic', 'unhealthy']\n",
    "\n",
    "train_data[attributes].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class UCC_Dataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, attributes, max_token_len: int = 128, sample = 5000):\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.attributes = attributes\n",
    "        self.max_token_len = max_token_len\n",
    "        self.sample = sample\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        data = pd.read_csv(self.data_path)\n",
    "        data['unhealthy'] = np.where(data['healthy'] == 1, 0, 1)\n",
    "        if self.sample is not None:\n",
    "            unhealthy = data.loc[data[self.attributes].sum(axis=1) > 0]\n",
    "            healthy = data.loc[data[self.attributes].sum(axis=1) == 0]\n",
    "            self.data = pd.concat([unhealthy, healthy.sample(n=self.sample, random_state=42)], ignore_index=True)\n",
    "        else:\n",
    "            self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        comment = str(item.comment)\n",
    "        attributes = torch.FloatTensor(item[self.attributes])\n",
    "        tokens = self.tokenizer.encode_plus(comment, \n",
    "                                            add_special_tokens=True, \n",
    "                                            return_tensors='pt',\n",
    "                                            truncation=True,\n",
    "                                            max_length=self.max_token_len,\n",
    "                                            padding='max_length',\n",
    "                                            return_attention_mask=True)\n",
    "        return {\n",
    "            'input_ids': tokens.input_ids.flatten(),\n",
    "            'attention_mask': tokens.attention_mask.flatten(),\n",
    "            'labels': attributes\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ucc_ds = UCC_Dataset(data_path='data/unhealthy_comment_corpus/train.csv', \n",
    "                     tokenizer=tokenizer, \n",
    "                     attributes=attributes)\n",
    "\n",
    "ucc_ds_val = UCC_Dataset(data_path='data/unhealthy_comment_corpus/test.csv', \n",
    "                         tokenizer=tokenizer, \n",
    "                         attributes=attributes, \n",
    "                         sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/gv_5rj1j60z6gsgwh0rqwgf80000gn/T/ipykernel_40090/1011466821.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  attributes = torch.FloatTensor(item[self.attributes])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0, 19897, 29846,     4,    38,    64,    75,   679, 46301,    74,\n",
       "          9802,   132,     9,    39,   308,    95,     7,  1471,   559,   332,\n",
       "             8,   146,  7064,   356,  1099,     4,   370,   214,   235,     6,\n",
       "         46301,    16,    10, 34759,     4,     2,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucc_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9960"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ucc_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCC_Data_Module(pl.LightningDataModule):\n",
    "    def __init__(self, train_path, val_path, attributes, batch_size: int = 16, max_token_len: int = 128, model_name: str = 'roberta-base'):\n",
    "        super().__init__()\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.attributes = attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        if stage in (None, 'fit'):\n",
    "            self.train_dataset = UCC_Dataset(data_path=self.train_path, \n",
    "                                             tokenizer=self.tokenizer, \n",
    "                                             attributes=self.attributes)\n",
    "            self.val_dataset = UCC_Dataset(data_path=self.val_path, \n",
    "                                            tokenizer=self.tokenizer, \n",
    "                                            attributes=self.attributes,\n",
    "                                            sample=None)\n",
    "        if stage == 'predict':\n",
    "            self.val_dataset = UCC_Dataset(data_path=self.val_path, \n",
    "                                            tokenizer=self.tokenizer, \n",
    "                                            attributes=self.attributes,\n",
    "                                            sample=None)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc_data_module = UCC_Data_Module(train_path='data/unhealthy_comment_corpus/train.csv', \n",
    "                                  val_path='data/unhealthy_comment_corpus/test.csv', \n",
    "                                  attributes=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ucc_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCC_Classifier(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(self.config['model_name'], return_dict=True)\n",
    "        self.hidden = nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
    "        self.classifier = nn.Linear(self.pretrained_model.config.hidden_size, self.config['n_labels'])\n",
    "        torch.nn.init.xavier_uniform_(self.hidden.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.dropout = nn.Dropout()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # roberta model\n",
    "        output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = torch.mean(output.last_hidden_state, dim=1)\n",
    "        # neural network classification layers\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        # calculate loss\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss_func(logits.view(-1, self.config['n_labels']), labels.view(-1, self.config['n_labels']))\n",
    "        return loss, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return {'loss': loss, \n",
    "                'predictions': logits,\n",
    "                'labels': batch['labels']}\n",
    "        \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log('validation_loss', loss, prog_bar=True, logger=True)\n",
    "        return {'validation_loss': loss, \n",
    "                'predictions': logits,\n",
    "                'labels': batch['labels']}\n",
    "        \n",
    "    def predict_step(self, batch, batch_index):\n",
    "        _, logits = self(**batch)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config['learning_rate'], weight_decay=self.config['weight_decay'])\n",
    "        total_steps = self.config['train_size'] / self.config['batch_size']\n",
    "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps=warmup_steps, \n",
    "                                                    num_training_steps=total_steps)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'distilroberta-base',\n",
    "    'n_labels': len(attributes),\n",
    "    'learning_rate': 1.5e-6,\n",
    "    'weight_decay': 0.001,\n",
    "    'warmup': 0.2,\n",
    "    'train_size': len(ucc_data_module.train_dataloader()),\n",
    "    'batch_size': 128,\n",
    "    'n_epochs': 100\n",
    "}\n",
    "\n",
    "model = UCC_Classifier(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/user/Library/Python/3.9/lib/python/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name             | Type              | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | pretrained_model | RobertaModel      | 82.1 M | eval \n",
      "1 | hidden           | Linear            | 590 K  | train\n",
      "2 | classifier       | Linear            | 6.2 K  | train\n",
      "3 | loss_func        | BCEWithLogitsLoss | 0      | train\n",
      "4 | dropout          | Dropout           | 0      | train\n",
      "---------------------------------------------------------------\n",
      "82.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.7 M    Total params\n",
      "330.861   Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "120       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'UCC_Dataset' on <module '__main__' (built-in)>\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/loops/evaluation_loop.py:122\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_start()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/loops/evaluation_loop.py:258\u001b[0m, in \u001b[0;36m_EvaluationLoop.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# add the previous `fetched` value to properly track `is_last_batch` with no prefetching\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/loops/fetchers.py:105\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_PrefetchDataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;66;03m# ignore pre-fetching, it's not necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/loops/fetchers.py:52\u001b[0m, in \u001b[0;36m_DataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_DataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombined_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/combined_loader.py:351\u001b[0m, in \u001b[0;36mCombinedLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflattened, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits)\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m iterator\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/combined_loader.py:155\u001b[0m, in \u001b[0;36m_Sequential.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_current_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/utilities/combined_loader.py:173\u001b[0m, in \u001b[0;36m_Sequential._load_current_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterables):\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# No more iterables to step through, return an empty list\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m                      num_sanity_val_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     14\u001b[0m                      logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m                      log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mucc_data_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# datamodule\n",
    "ucc_data_module = UCC_Data_Module(train_path='data/unhealthy_comment_corpus/train.csv', \n",
    "                                  val_path='data/unhealthy_comment_corpus/test.csv', \n",
    "                                  batch_size=config['batch_size'], \n",
    "                                  attributes=attributes)\n",
    "ucc_data_module.setup()\n",
    "\n",
    "# model\n",
    "model = UCC_Classifier(config=config)\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'],\n",
    "                     num_sanity_val_steps=50,\n",
    "                     logger=True,\n",
    "                     log_every_n_steps=10)\n",
    "\n",
    "trainer.fit(model, ucc_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
